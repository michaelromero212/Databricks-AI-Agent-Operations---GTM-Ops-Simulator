# Databricks AI Agent Operations & GTM Ops Simulator

A production-style **AI Agent Operations & GTM Ops Simulator** demonstrating how AI agents are defined, governed, QA'd, monitored, and rolled out inside a sales-facing environment.

This project showcases **AI Operations, QA, governance, KPIs, dashboards, A/B testing, enablement, and GTM readiness** for a modern data and AI company.

## âœ¨ What's New (January 2026)

### Premium UI Overhaul
- **Databricks-Inspired Design** - Professional sidebar navigation with deep blue/orange color palette
- **Interactive Chart.js Visualizations** - Bar charts, doughnut charts, and trend lines with real-time data
- **SQL Explorer** - Query agent run data directly with preset templates and schema reference
- **Live Feedback Loop** - Every agent test logs to the database, updating dashboards in real-time

### Key Features Added
| Feature | Description |
|---------|-------------|
| ğŸ¨ Sidebar Navigation | Persistent nav with Overview, Dashboard, Test Agent, SQL Explorer |
| ğŸ“Š Interactive Charts | A/B Test Comparison, Performance by Task Type, Daily Trends |
| ğŸ” SQL Explorer | Run SQL queries against `agent_runs` with preset query templates |
| âš¡ Live Data Loop | Agent tests automatically append to CSV and reflect in metrics |
| ğŸ§ª A/B Test Results | Visual comparison of Agent A vs Agent B with decision recommendation |

## ğŸ¯ Project Overview

This simulator demonstrates:

- **Business Intent & Governance** - How AI agent behavior is defined and constrained
- **AI Agent Operations** - Agent implementation using Hugging Face LLMs
- **QA & Validation** - Pre-deployment testing and validation workflows
- **KPIs & Analytics** - SQL-based metrics tracking and analysis
- **Dashboards** - Operational health monitoring with interactive visualizations
- **A/B Testing** - Data-driven rollout decisions with statistical analysis
- **Enablement** - User guidance and business reviews

## ğŸ—ï¸ Project Structure

```
Databricks-AI-Agent-Operations-&-GTM-Ops-Simulator/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore                         # Git exclusions
â”‚
â”œâ”€â”€ docs/                              # Business documentation
â”‚   â”œâ”€â”€ business_intent.md            # Agent definition & governance
â”‚   â”œâ”€â”€ kpis.md                       # KPI definitions
â”‚   â”œâ”€â”€ rollout_plan.md               # Deployment strategy
â”‚   â””â”€â”€ enablement.md                 # User guidance
â”‚
â”œâ”€â”€ agent/                             # AI Agent implementation
â”‚   â”œâ”€â”€ agent.py                      # Core agent logic
â”‚   â””â”€â”€ prompts.py                    # Prompt templates
â”‚
â”œâ”€â”€ qa/                                # Quality assurance
â”‚   â”œâ”€â”€ test_cases.json               # Structured test cases
â”‚   â””â”€â”€ run_qa.py                     # QA test runner
â”‚
â”œâ”€â”€ data/                              # Data storage
â”‚   â”œâ”€â”€ sample_agent_runs.csv         # Sample agent interaction data
â”‚   â””â”€â”€ uploaded_inputs/              # User-uploaded files
â”‚
â”œâ”€â”€ analytics/                         # Data analytics
â”‚   â”œâ”€â”€ load_data.py                  # Data ingestion (DuckDB)
â”‚   â””â”€â”€ queries.sql                   # SQL queries for KPIs
â”‚
â”œâ”€â”€ dashboards/                        # Visualization
â”‚   â””â”€â”€ kpi_dashboard.ipynb           # Jupyter dashboard
â”‚
â”œâ”€â”€ experiments/                       # A/B testing
â”‚   â””â”€â”€ ab_test.md                    # Experiment documentation
â”‚
â”œâ”€â”€ reviews/                           # Business reviews
â”‚   â””â”€â”€ weekly_business_review.md     # Review template
â”‚
â””â”€â”€ webapp/                            # Web application
    â”œâ”€â”€ app.py                        # FastAPI application
    â”œâ”€â”€ templates/                    # Jinja2 templates
    â”‚   â”œâ”€â”€ layout.html              # Shared layout with sidebar
    â”‚   â”œâ”€â”€ index.html               # Overview page
    â”‚   â”œâ”€â”€ dashboard.html           # KPI dashboard
    â”‚   â”œâ”€â”€ upload.html              # Test agent page
    â”‚   â””â”€â”€ explorer.html            # SQL Explorer
    â””â”€â”€ static/
        â””â”€â”€ styles.css               # Premium CSS design system
```

## ğŸš€ Quick Start

### 1. Clone & Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/Databricks-AI-Agent-Operations-GTM-Ops-Simulator.git
cd Databricks-AI-Agent-Operations-GTM-Ops-Simulator

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Hugging Face Token (Optional)

```bash
export HF_TOKEN="your_huggingface_token_here"
```

Get a free token from [Hugging Face](https://huggingface.co/settings/tokens). The agent works without a token using mock responses.

### 3. Run the Web Application

```bash
cd webapp
HF_TOKEN=your_token uvicorn app:app --host 0.0.0.0 --port 8000
```

Open your browser to: **http://localhost:8000**

## ğŸ“¸ Screenshots

### Performance Overview (Home Page)
The landing page shows real-time KPIs, A/B test comparisons, lead source performance, and recent activityâ€”all with interactive Chart.js visualizations.

![Home Page](docs/images/home_page.jpg)

### KPI Dashboard
Comprehensive metrics including Task Accuracy (92%), User Satisfaction (4.18/5), Resolution Time, and Error Rate. Interactive bar charts compare Agent A vs Agent B performance.

![KPI Dashboard](docs/images/dashboard_kpis.jpg)

### SQL Explorer
Query the `agent_runs` data directly using SQL. Includes preset query buttons for common analyses and a full schema reference.

![SQL Explorer](docs/images/sql_explorer.jpg)

### Test Agent
Upload lead data, deal notes, or sales inputs to test the AI agent. Select a task type and receive real LLM-powered analysis with feedback buttons.

![Upload Page](docs/images/upload_page.jpg)

### AI Agent Response
Real AI-generated analysis from the Llama-3.2 model. Includes Company Overview, Industry & Use Case Fit, Suggested Questions, and Recommended Next Steps.

![Agent Response](docs/images/agent_response.jpg)

## ğŸ¯ Role Alignment: AI Operations Program Manager

This project demonstrates core competencies for **AI Operations** roles:

| Competency | Demonstration |
|------------|---------------|
| **Lifecycle Management** | From Business Intent to Field Enablement |
| **Analytical Monitoring** | SQL-driven dashboards for KPI optimization |
| **Governance & Accountability** | QA tests, human-in-the-loop escalation, UAT |
| **A/B Testing** | Data-driven decisions with Agent A vs B comparison |
| **Continuous Improvement** | Prompt iteration logs based on field feedback |
| **Stakeholder Leadership** | Weekly Business Review templates |

## ğŸš€ Key Features

### ğŸ¤– AI Agent
- Accepts GTM tasks: lead summaries, follow-up suggestions, deal risk signals
- Uses Hugging Face LLMs (Llama-3.2-3B-Instruct)
- Implements governance rules and escalation logic
- Falls back to mock responses without token

### ğŸ“Š Interactive Dashboards
- **Overview**: Quick KPI snapshot, A/B comparison charts, recent activity
- **Dashboard**: Detailed metrics, trends, task type breakdown
- **SQL Explorer**: Direct data querying with preset templates
- **Live Updates**: Every test agent run updates the dashboards

### ğŸ” SQL Explorer
Run queries directly against the agent data:
```sql
SELECT lead_source, COUNT(*) as volume, 
       ROUND(AVG(CASE WHEN user_accepted THEN 1.0 ELSE 0.0 END) * 100, 1) as accuracy
FROM agent_runs 
GROUP BY lead_source
ORDER BY accuracy DESC
```

### ğŸ§ª A/B Testing
- Real-time comparison of Agent A (control) vs Agent B (experimental)
- Visual charts showing accuracy, satisfaction, and error rates
- Decision recommendations based on success criteria
- Detailed analysis in `experiments/ab_test.md`

### âœ… QA & Validation
- Structured test cases in JSON
- Automated test runner
- Accuracy, hallucination, and rule violation tracking
- Results feed into analytics pipeline

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | FastAPI + Python |
| Frontend | Jinja2 + Chart.js |
| Database | DuckDB (in-memory SQL) |
| LLM | Hugging Face Inference API |
| Styling | Custom CSS (Databricks-inspired) |
| Data Format | CSV with live appends |

## ğŸ”’ Security & Best Practices

- âœ… Secrets via environment variables (no credentials in code)
- âœ… Input validation and SQL injection prevention
- âœ… Virtual environment isolation
- âœ… Rate limiting and security headers
- âœ… Professional error handling

## ğŸ§ª Running QA Tests

```bash
python qa/run_qa.py
```

## ğŸ“ˆ Viewing Analytics (CLI)

```bash
python analytics/load_data.py
```

This loads data into DuckDB and executes queries from `analytics/queries.sql`.

## ğŸ“ Documentation

See the `docs/` directory for detailed documentation:

- **business_intent.md** - Agent definition, rules, and success criteria
- **kpis.md** - Metric definitions and tracking methodology
- **rollout_plan.md** - Phased deployment strategy
- **enablement.md** - User training and guidance
- **experiments/ab_test.md** - A/B test methodology and results

## ğŸ¤ Contributing

This is a demonstration project. Feel free to fork and adapt for your own use cases.

## ğŸ“„ License

MIT License - See LICENSE file for details

---

**Built to demonstrate AI Operations excellence in GTM environments**

*Last Updated: January 2026*
