{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI Agent KPI Dashboard\\n",
                "\\n",
                "Operational metrics and analytics for GTM AI Agent performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\\n",
                "import matplotlib.pyplot as plt\\n",
                "import seaborn as sns\\n",
                "import sys\\n",
                "from pathlib import Path\\n",
                "\\n",
                "# Add analytics directory to path\\n",
                "sys.path.insert(0, str(Path.cwd().parent / 'analytics'))\\n",
                "from load_data import DataLoader\\n",
                "\\n",
                "# Configure plotting style\\n",
                "sns.set_style('whitegrid')\\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\\n",
                "plt.rcParams['font.size'] = 10\\n",
                "\\n",
                "print('✅ Imports complete')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize data loader\\n",
                "data_file = Path.cwd().parent / 'data' / 'sample_agent_runs.csv'\\n",
                "loader = DataLoader(':memory:')\\n",
                "df = loader.load_csv_to_db(str(data_file))\\n",
                "\\n",
                "print(f'Loaded {len(df)} agent runs')\\n",
                "print(f'Date range: {df[\"timestamp\"].min()} to {df[\"timestamp\"].max()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Overall Summary Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary = loader.get_summary_stats()\\n",
                "display(summary)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## A/B Test Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ab_comparison = loader.get_metrics_by_version()\\n",
                "display(ab_comparison)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize A/B comparison\\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n",
                "\\n",
                "# Accuracy comparison\\n",
                "axes[0, 0].bar(ab_comparison['agent_version'], ab_comparison['accuracy_pct'], color=['#1f77b4', '#ff7f0e'])\\n",
                "axes[0, 0].axhline(y=85, color='green', linestyle='--', label='Target (85%)')\\n",
                "axes[0, 0].set_ylabel('Accuracy (%)')\\n",
                "axes[0, 0].set_title('Task Accuracy by Agent Version')\\n",
                "axes[0, 0].legend()\\n",
                "axes[0, 0].set_ylim([0, 100])\\n",
                "\\n",
                "# Satisfaction comparison\\n",
                "axes[0, 1].bar(ab_comparison['agent_version'], ab_comparison['avg_satisfaction'], color=['#1f77b4', '#ff7f0e'])\\n",
                "axes[0, 1].axhline(y=4.0, color='green', linestyle='--', label='Target (4.0)')\\n",
                "axes[0, 1].set_ylabel('Avg Satisfaction (1-5)')\\n",
                "axes[0, 1].set_title('User Satisfaction by Agent Version')\\n",
                "axes[0, 1].legend()\\n",
                "axes[0, 1].set_ylim([0, 5])\\n",
                "\\n",
                "# Resolution time comparison\\n",
                "axes[1, 0].bar(ab_comparison['agent_version'], ab_comparison['avg_resolution_time'], color=['#1f77b4', '#ff7f0e'])\\n",
                "axes[1, 0].axhline(y=5.0, color='green', linestyle='--', label='Target (<5s)')\\n",
                "axes[1, 0].set_ylabel('Avg Resolution Time (s)')\\n",
                "axes[1, 0].set_title('Resolution Speed by Agent Version')\\n",
                "axes[1, 0].legend()\\n",
                "\\n",
                "# Error rate comparison\\n",
                "axes[1, 1].bar(ab_comparison['agent_version'], ab_comparison['error_rate'], color=['#1f77b4', '#ff7f0e'])\\n",
                "axes[1, 1].axhline(y=2.0, color='green', linestyle='--', label='Target (<2%)')\\n",
                "axes[1, 1].set_ylabel('Error Rate (%)')\\n",
                "axes[1, 1].set_title('Error Rate by Agent Version')\\n",
                "axes[1, 1].legend()\\n",
                "axes[1, 1].set_ylim([0, 5])\\n",
                "\\n",
                "plt.tight_layout()\\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Performance by Task Type"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "by_task = loader.get_metrics_by_task_type()\\n",
                "display(by_task)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize task type performance\\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n",
                "\\n",
                "# Task volume\\n",
                "axes[0].barh(by_task['task_type'], by_task['total_tasks'], color='steelblue')\\n",
                "axes[0].set_xlabel('Total Tasks')\\n",
                "axes[0].set_title('Task Volume by Type')\\n",
                "\\n",
                "# Accuracy by task type\\n",
                "axes[1].barh(by_task['task_type'], by_task['accuracy_pct'], color='seagreen')\\n",
                "axes[1].axvline(x=85, color='red', linestyle='--', label='Target (85%)')\\n",
                "axes[1].set_xlabel('Accuracy (%)')\\n",
                "axes[1].set_title('Task Accuracy by Type')\\n",
                "axes[1].legend()\\n",
                "axes[1].set_xlim([0, 100])\\n",
                "\\n",
                "plt.tight_layout()\\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Daily Trends"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trends = loader.get_daily_trends()\\n",
                "trends['date'] = pd.to_datetime(trends['date'])\\n",
                "display(trends)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize daily trends\\n",
                "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\\n",
                "\\n",
                "# Task volume trend\\n",
                "axes[0].plot(trends['date'], trends['total_tasks'], marker='o', color='steelblue', linewidth=2)\\n",
                "axes[0].set_ylabel('Total Tasks')\\n",
                "axes[0].set_title('Daily Task Volume')\\n",
                "axes[0].grid(True, alpha=0.3)\\n",
                "\\n",
                "# Accuracy trend\\n",
                "axes[1].plot(trends['date'], trends['accuracy_pct'], marker='o', color='seagreen', linewidth=2)\\n",
                "axes[1].axhline(y=85, color='red', linestyle='--', label='Target (85%)', alpha=0.7)\\n",
                "axes[1].set_ylabel('Accuracy (%)')\\n",
                "axes[1].set_title('Daily Task Accuracy')\\n",
                "axes[1].set_ylim([0, 100])\\n",
                "axes[1].legend()\\n",
                "axes[1].grid(True, alpha=0.3)\\n",
                "\\n",
                "# Active users trend\\n",
                "axes[2].plot(trends['date'], trends['active_users'], marker='o', color='darkorange', linewidth=2)\\n",
                "axes[2].set_ylabel('Active Users')\\n",
                "axes[2].set_xlabel('Date')\\n",
                "axes[2].set_title('Daily Active Users')\\n",
                "axes[2].grid(True, alpha=0.3)\\n",
                "\\n",
                "plt.tight_layout()\\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## User Satisfaction Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate satisfaction distribution\\n",
                "satisfaction_dist = df[df['user_rating'].notna()]['user_rating'].value_counts().sort_index(ascending=False)\\n",
                "\\n",
                "# Plot\\n",
                "plt.figure(figsize=(10, 6))\\n",
                "bars = plt.barh(satisfaction_dist.index.astype(str) + ' stars', satisfaction_dist.values, color='skyblue')\\n",
                "plt.xlabel('Count')\\n",
                "plt.title('User Satisfaction Distribution')\\n",
                "\\n",
                "# Add percentage labels\\n",
                "total = satisfaction_dist.sum()\\n",
                "for i, (bar, count) in enumerate(zip(bars, satisfaction_dist.values)):\\n",
                "    pct = count / total * 100\\n",
                "    plt.text(count + 0.2, bar.get_y() + bar.get_height()/2, f'{pct:.1f}%', va='center')\\n",
                "\\n",
                "plt.tight_layout()\\n",
                "plt.show()\\n",
                "\\n",
                "print(f'Average satisfaction: {df[\"user_rating\"].mean():.2f} / 5.0')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Key Insights\\n",
                "\\n",
                "Based on the data analysis:\\n",
                "\\n",
                "### Positive Signals\\n",
                "- Task accuracy consistently above 85% target\\n",
                "- User satisfaction strong at 4.0+ average\\n",
                "- Resolution speed well under 5s target\\n",
                "- Low error rate (<2%)\\n",
                "\\n",
                "### Areas for Improvement\\n",
                "- User adoption growing but below Phase 1 target\\n",
                "- Agent B variant did not outperform Agent A in current test\\n",
                "- Need more sample size for confident A/B conclusions\\n",
                "\\n",
                "### Recommendations\\n",
                "1. Continue with Agent A while iterating on Agent B based on feedback\\n",
                "2. Drive adoption through enablement and manager endorsement\\n",
                "3. Extend A/B test duration to reach statistical significance\\n",
                "4. Consider Phase 2 rollout to SDR team given strong metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Close database connection\\n",
                "loader.close()\\n",
                "print('✅ Dashboard complete')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}